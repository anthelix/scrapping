{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anthelix/Documents/projetGit/WebScraping\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"http://books.toscrape.com/index.html\"\n",
    "result = requests.get(main_url)\n",
    "scraped = BeautifulSoup(result.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAndParseURL(url):\n",
    "    response = requests.get(url)\n",
    "    scraped = BeautifulSoup(response.text, 'html.parser')\n",
    "    return(scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fetched products URLs\n",
      "One example:\n",
      "../neither-here-nor-there-travels-in-europe_198/index.html\n"
     ]
    }
   ],
   "source": [
    "#Find book URLs on the main page\n",
    "scraped.find(\"article\", class_ = \"product_pod\").div.a.get('href')\n",
    "main_page_products_urls = [x.div.a.get('href') for x in scraped.findAll(\"article\", class_ = \"product_pod\")]\n",
    "print(str(len(main_page_products_urls)) + \" fetched products URLs\")\n",
    "print(\"One example:\")\n",
    "print(main_page_products_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBooksURLs(url):\n",
    "    '''\n",
    "    retrieve book links on any given page of the website\n",
    "    '''\n",
    "    scraped = getAndParseURL(url)\n",
    "    # remove the index.html part of the base url before returning the results\n",
    "    return([\"/\".join(url.split(\"/\")[:-1]) + \"/\" + x.div.a.get('href') for x in scraped.findAll(\"article\", class_ = \"product_pod\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched categories URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/index.htmlcatalogue/category/books/travel_2/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/mystery_3/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/historical-fiction_4/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/sequential-art_5/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/classics_6/index.html']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find book categories URLs on the main page\n",
    "# Getting the URLs of subsections of a website can be very useful if we want to scrape a specific part of it\n",
    "categories_urls = [main_url + x.get('href') for x in scraped.find_all(\"a\", href=re.compile(\"catalogue/category/books\"))]\n",
    "categories_urls = categories_urls[1:] # we remove the first one because it corresponds to all the books\n",
    "\n",
    "print(str(len(categories_urls)) + \" fetched categories URLs\")\n",
    "print(\"Some examples:\")\n",
    "categories_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/index.html',\n",
       " 'http://books.toscrape.com/catalogue/page-2.html',\n",
       " 'http://books.toscrape.com/catalogue/page-3.html',\n",
       " 'http://books.toscrape.com/catalogue/page-4.html',\n",
       " 'http://books.toscrape.com/catalogue/page-5.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all pages URLs\n",
    "# store all the results into a list\n",
    "pages_urls = [main_url]\n",
    "\n",
    "scraped = getAndParseURL(pages_urls[0])\n",
    "\n",
    "# while we get two matches, this means that the webpage contains a 'previous' and a 'next' button\n",
    "# if there is only one button, this means that we are either on the first page or on the last page\n",
    "# we stop when we get to the last page\n",
    "\n",
    "while len(scraped.findAll(\"a\", href=re.compile(\"page\"))) == 2 or len(pages_urls) == 1:\n",
    "    \n",
    "    # get the new complete url by adding the fetched URL to the base URL (and removing the .html part of the base URL)\n",
    "    new_url = \"/\".join(pages_urls[-1].split(\"/\")[:-1]) + \"/\" + scraped.findAll(\"a\", href=re.compile(\"page\"))[-1].get(\"href\")\n",
    "    \n",
    "    # add the URL to the list\n",
    "    pages_urls.append(new_url)\n",
    "    \n",
    "    # parse the next page\n",
    "    scraped = getAndParseURL(new_url)\n",
    "    \n",
    "\n",
    "print(str(len(pages_urls)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "pages_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code for page 50: 200\n",
      "status code for page 51: 404\n"
     ]
    }
   ],
   "source": [
    "#We could have just created this list by incrementing ‘page-X.html’ until 50.\n",
    "#but if the number of pages changes??\n",
    "#One solution could be to increment the value until we get on a 404 page.\n",
    "#The 200 code indicates that there is no error. The 404 code tells us that the page was not found.\n",
    "result = requests.get(\"http://books.toscrape.com/catalogue/page-50.html\")\n",
    "print(\"status code for page 50: \" + str(result.status_code))\n",
    "\n",
    "result = requests.get(\"http://books.toscrape.com/catalogue/page-51.html\")\n",
    "print(\"status code for page 51: \" + str(result.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/page-1.html',\n",
       " 'http://books.toscrape.com/catalogue/page-2.html',\n",
       " 'http://books.toscrape.com/catalogue/page-3.html',\n",
       " 'http://books.toscrape.com/catalogue/page-4.html',\n",
       " 'http://books.toscrape.com/catalogue/page-5.html']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with the changes\n",
    "pages_urls = []\n",
    "\n",
    "new_page = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "while requests.get(new_page).status_code == 200:\n",
    "    pages_urls.append(new_page)\n",
    "    new_page = pages_urls[-1].split(\"-\")[0] + \"-\" + str(int(pages_urls[-1].split(\"-\")[1].split(\".\")[0]) + 1) + \".html\"\n",
    "    \n",
    "\n",
    "print(str(len(pages_urls)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "pages_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html',\n",
       " 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html',\n",
       " 'http://books.toscrape.com/catalogue/soumission_998/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sharp-objects_997/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all products URLs\n",
    "\n",
    "booksURLs = []\n",
    "for page in pages_urls:\n",
    "    booksURLs.extend(getBooksURLs(page))\n",
    "    \n",
    "print(str(len(booksURLs)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "booksURLs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>nb_in_stock</th>\n",
       "      <th>url_img</th>\n",
       "      <th>product_category</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>22</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "      <td>poetry_23</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "      <td>historical-fiction_4</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "      <td>fiction_10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "      <td>mystery_3</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>20</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "      <td>history_32</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  price nb_in_stock  \\\n",
       "0                   A Light in the Attic  51.77          22   \n",
       "1                     Tipping the Velvet  53.74          20   \n",
       "2                             Soumission  50.10          20   \n",
       "3                          Sharp Objects  47.82          20   \n",
       "4  Sapiens: A Brief History of Humankind  54.23          20   \n",
       "\n",
       "                                             url_img      product_category  \\\n",
       "0  http://books.toscrape.com/catalogue/a-light-in...             poetry_23   \n",
       "1  http://books.toscrape.com/catalogue/tipping-th...  historical-fiction_4   \n",
       "2  http://books.toscrape.com/catalogue/soumission...            fiction_10   \n",
       "3  http://books.toscrape.com/catalogue/sharp-obje...             mystery_3   \n",
       "4  http://books.toscrape.com/catalogue/sapiens-a-...            history_32   \n",
       "\n",
       "  rating  \n",
       "0  Three  \n",
       "1    One  \n",
       "2    One  \n",
       "3   Four  \n",
       "4   Five  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get product data     book title, price, availability, image, category, rating\n",
    "names = []\n",
    "prices = []\n",
    "nb_in_stock = []\n",
    "img_urls = []\n",
    "categories = []\n",
    "ratings = []\n",
    "\n",
    "# scrape data for every book URL: this may take some time\n",
    "for url in booksURLs:\n",
    "    scraped = getAndParseURL(url)\n",
    "    # product name\n",
    "    names.append(scraped.find(\"div\", class_ = re.compile(\"product_main\")).h1.text)\n",
    "    # product price\n",
    "    prices.append(scraped.find(\"p\", class_ = \"price_color\").text[2:]) # get rid of the pound sign\n",
    "    # number of available products\n",
    "    nb_in_stock.append(re.sub(\"[^0-9]\", \"\", scraped.find(\"p\", class_ = \"instock availability\").text)) # get rid of non numerical characters\n",
    "    # image url\n",
    "    img_urls.append(url.replace(\"index.html\", \"\") + scraped.find(\"img\").get(\"src\"))\n",
    "    # product category\n",
    "    categories.append(scraped.find(\"a\", href = re.compile(\"../category/books/\")).get(\"href\").split(\"/\")[3])\n",
    "    # ratings\n",
    "    ratings.append(scraped.find(\"p\", class_ = re.compile(\"star-rating\")).get(\"class\")[1])\n",
    "    \n",
    "# add data into pandas df\n",
    "import pandas as pd\n",
    "\n",
    "scraped_data = pd.DataFrame({'name': names, 'price': prices, 'nb_in_stock': nb_in_stock, \"url_img\": img_urls, \"product_category\": categories, \"rating\": ratings})\n",
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data cleaning may be useful before using them:\n",
    "\n",
    "    transform the ratings into numerical values\n",
    "    remove the numbers in the product_category column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/jonathanoheix/scraping_basics_with_beautifulsoup/blob/master/scraping_basics_with_beautifulsoup.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('psyco': conda)",
   "language": "python",
   "name": "python38564bitpsycoconda75b9efcc41a341f4afc4eb40c858c4ca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
